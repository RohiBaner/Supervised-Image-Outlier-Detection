{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os , sys,cv2\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import csv\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import shutil\n",
    "\n",
    "# Create lists to store the filenames from respective folders\n",
    "inlier_files=[]\n",
    "outlier_files=[]\n",
    "# Append all filenames from inliner_train data\n",
    "inlier_path = \"./inlier_train/\"\n",
    "for i in os.listdir(inlier_path):\n",
    "    inlier_files.append(i)\n",
    "# Append all filenames from outlier_train data\n",
    "outlier_path = \"./outlier_train/\"\n",
    "for i in os.listdir(outlier_path):\n",
    "    outlier_files.append(i)\n",
    "# Create new folder to store the augmented outlier data\n",
    "try:\n",
    "    os.mkdir(\"./augmented\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "# Create new folder to store the final training data images (inliers+outliers+augmented images)\n",
    "try:\n",
    "    os.mkdir(\"./train\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "# Data Augmentation factors\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=120,\n",
    "        zoom_range=0.4,\n",
    "        zca_epsilon=1e-6,\n",
    "        horizontal_flip=True,\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        fill_mode='nearest')\n",
    "# Create augmented image for each outlier image\n",
    "for imagefile in outlier_files:\n",
    "    name = './outlier_train/' + imagefile\n",
    "    img = load_img(name,target_size=(224, 224))  \n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)  \n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,save_to_dir='./augmented/', save_prefix='aug_', save_format='jpeg'):\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            break\n",
    "# Get all the filenames for the augmented images\n",
    "aug_files = []\n",
    "aug_path = \"./augmented/\"\n",
    "for i in os.listdir(aug_path):\n",
    "    aug_files.append(i)\n",
    "# Label all augmented images with label = 1\n",
    "df_o = pd.DataFrame(outlier_files, columns=['filename'])\n",
    "df_o['label'] = 1\n",
    "# Label all outlier images with label = 1\n",
    "df_a = pd.DataFrame(aug_files, columns=['filename'])\n",
    "df_a['label'] = 1\n",
    "# Label all inlier images with label = 0\n",
    "df_i = pd.DataFrame(inlier_files, columns=['filename'])\n",
    "df_i['label'] = 0\n",
    "# Merge all images filenames and label (augmented+outlier+inlier) to one dataframe\n",
    "df_train = pd.concat([df_a,df_o,df_i], axis=0, ignore_index=True)\n",
    "# Shift all augmented datafiles to train folder\n",
    "source = './augmented/'\n",
    "dest1 = './train/'\n",
    "files = os.listdir(source)\n",
    "for f in files:\n",
    "        shutil.copy(source+f, dest1)\n",
    "# Shift all outlier datafiles to train folder        \n",
    "source = './outlier_train/'\n",
    "dest1 = './train/'\n",
    "files = os.listdir(source)\n",
    "for f in files:\n",
    "        shutil.copy(source+f, dest1)\n",
    "# Shift all inlier datafiles to train folder\n",
    "source = './inlier_train/'\n",
    "dest1 = './train/'\n",
    "files = os.listdir(source)\n",
    "for f in files:\n",
    "        shutil.copy(source+f, dest1)\n",
    "# Get the final filename (image name) for all training data\n",
    "filename = df_train.filename.values\n",
    "# Get all labels for all training data\n",
    "label = df_train.label.values\n",
    "\n",
    "# Function to get the image size in the train image directory\n",
    "def file_size_train(file_name):\n",
    "    stats=os.stat(\"train/\"+str(file_name))\n",
    "    return stats.st_size\n",
    "\n",
    "# Function to call the keras pre-trained model to get feature weights of the train images\n",
    "def resnet_model_train():\n",
    "    n=0\n",
    "    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "    images_path = \"./train\"\n",
    "    # Looping over every image present in the files list\n",
    "    for img_path in filename:\n",
    "        if(file_size_train(img_path)!=0):\n",
    "            print(str(img_path))\n",
    "            n+=1\n",
    "            print(n)\n",
    "            # load the image and resize it\n",
    "            img = image.load_img(\"./train/\"+str(img_path), target_size=(224, 224))\n",
    "            # extract features from each image\n",
    "            x_image = image.img_to_array(img)\n",
    "            x_image = np.expand_dims(x_image, axis=0) # increase dimensions of x to make it suitable for further feature extraction\n",
    "            x_image = preprocess_input(x_image)\n",
    "            x_features = model.predict(x_image) # extract image features from model\n",
    "            x_features = np.array(x_features) # convert features list to numpy array\n",
    "            x_flatten= x_features.flatten() # flatten out the features in x\n",
    "            train_features.append(x_flatten) # this list contains the final features of the training images\n",
    "\n",
    "# Function to get the image size in the test image directory\n",
    "def file_size_test(file_name):\n",
    "    stats=os.stat(\"test/\"+str(file_name))\n",
    "    return stats.st_size\n",
    "\n",
    "# Function to call the keras pre-trained model to get feature weights of the test images\n",
    "def resnet_model_test():\n",
    "    n=0\n",
    "    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "    images_path = \"./test\"\n",
    "    for f in os.listdir(images_path):\n",
    "        test_files.append(f)\n",
    "    # Looping over every image present in the files list\n",
    "    for img_path in test_files:\n",
    "        if(file_size_test(img_path)!=0):\n",
    "            print(str(img_path))\n",
    "            n+=1\n",
    "            print(n)\n",
    "            # load the image and resize it\n",
    "            img = image.load_img(\"./test/\"+str(img_path), target_size=(224, 224))\n",
    "            # extract features from each image\n",
    "            x_image = image.img_to_array(img)\n",
    "            x_image = np.expand_dims(x_image, axis=0) # increase dimensions of x to make it suitable for further feature extraction\n",
    "            x_image = preprocess_input(x_image)\n",
    "            x_features = model.predict(x_image) # extract image features from model\n",
    "            x_features = np.array(x_features) # convert features list to numpy array\n",
    "            x_flatten= x_features.flatten() # flatten out the features in x\n",
    "            test_features.append(x_flatten) # this list contains the final features of the test images\n",
    "\n",
    "train_features=[]\n",
    "resnet_model_train() # Call function to extract features of training images\n",
    "\n",
    "ss = StandardScaler()\n",
    "train_features = ss.fit_transform(train_features) # Scale training dataset\n",
    "\n",
    "test_features=[]\n",
    "test_files = []\n",
    "resnet_model_test() # Call function to extract features of testing images\n",
    "test_features = ss.transform(test_features) #scale testing dataset\n",
    "\n",
    "# Call the KNN classification model\n",
    "model_knn = KNeighborsClassifier(n_neighbors=2) # Using 2 neighbors as it is binary classification\n",
    "model_knn.fit(train_features,label) # Train the model\n",
    "pred_knn = model_knn.predict(test_features) # Predict the labels for the test image features\n",
    "\n",
    "# Write the results in a CSV in the specified format\n",
    "result = pd.DataFrame(pred_knn, columns=['Result'])\n",
    "result.reset_index(inplace=True)\n",
    "result.columns = ['ID', 'Result']\n",
    "result.to_csv('output.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
